{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 4 - Fourth.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "##Third Iteration\n",
        "\n",
        "**Changes:**\n",
        "- Dropout after every layer\n",
        "- Change Batch Size\n",
        "- Structural change in model\n",
        "\n",
        "**Expectations:**\n",
        "- A (mostly) underfit model (since dropout is active for every layer)\n",
        "- Higher accuracy\n",
        "\n",
        "**Result**:\n",
        "- Parameters: 14,708\n",
        "- Epochs Run: 50\n",
        "- Best Epoch: 22\n",
        "- Training Accuracy: 99.46\n",
        "- Validation Accuracy: 99.49\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install and Import Keras\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the required libraries\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3KOoBh_CFca",
        "colab_type": "code",
        "outputId": "b8920cf7-1728-4bbc-a8d1-72bf8f529a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Connecting Drive to save models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "b628dd8a-42b7-49be-c4e1-0f437edf5174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# Looking at sample images\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[24])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa920361b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Ii/EBQhB8IivADQf0XedIQ5bb80EMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining shape of the sets\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling down pixel values from 0-255 to 0-1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "3289cd00-a093-4502-c1df-b7afd46427f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Inspecting labels\n",
        "y_train[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "c481dd22-8a28-402f-aafe-091436218a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Inspectingt the categorized labels\n",
        "Y_train[20:30]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "6b52bb8c-c37c-4ea7-c011-97ef6d9bbb46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "# Building the infrastructure\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(8, 3, activation='relu', input_shape=(28,28,1), name = \"C3-1\")) #26\n",
        "model.add(BatchNormalization(name = \"BN-C3-1\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C3-1\"))\n",
        "\n",
        "model.add(Convolution2D(16, 3, activation='relu', name = \"C3-2\")) #24\n",
        "model.add(BatchNormalization(name = \"BN-C3-2\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C3-2\"))\n",
        "\n",
        "model.add(Convolution2D(16, 3, activation='relu', name = \"C3-3\")) #22\n",
        "model.add(BatchNormalization(name = \"BN-C3-3\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C3-3\"))\n",
        "\n",
        "model.add(MaxPooling2D(2, name = \"MP1\")) #11\n",
        "\n",
        "model.add(Convolution2D(8, 1, activation='relu', name = \"C1-1\")) #11\n",
        "model.add(BatchNormalization(name = \"BN-C1-1\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C1-1\"))\n",
        "\n",
        "model.add(Convolution2D(16, 3, activation='relu', name = \"C3-4\")) #9\n",
        "model.add(BatchNormalization(name = \"BN-C3-4\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C3-4\"))\n",
        "\n",
        "# model.add(MaxPooling2D(2, name = \"MP2\")) #5\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu', name = \"C1-2\")) #9\n",
        "model.add(BatchNormalization(name = \"BN-C1-2\"))\n",
        "model.add(Dropout(0.1, name = \"DO-1-2\"))\n",
        "\n",
        "model.add(Convolution2D(16, 3, activation='relu', name = \"C3-5\")) #7\n",
        "model.add(BatchNormalization(name = \"BN-C3-5\"))\n",
        "model.add(Dropout(0.1, name = \"DO-C3-5\"))\n",
        "\n",
        "model.add(Convolution2D(10, 7, name = \"C7-1\")) #1\n",
        "# model.add(BatchNormalization(name = \"BN-C7-1\"))\n",
        "# model.add(Dropout(0.1, name = \"DO-C7-1\"))\n",
        "\n",
        "model.add(Flatten(name = \"F\"))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Checking the model\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "C3-1 (Conv2D)                (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "BN-C3-1 (BatchNormalization) (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "DO-C3-1 (Dropout)            (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "C3-2 (Conv2D)                (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "BN-C3-2 (BatchNormalization) (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "DO-C3-2 (Dropout)            (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "C3-3 (Conv2D)                (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "BN-C3-3 (BatchNormalization) (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "DO-C3-3 (Dropout)            (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "MP1 (MaxPooling2D)           (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "C1-1 (Conv2D)                (None, 11, 11, 8)         136       \n",
            "_________________________________________________________________\n",
            "BN-C1-1 (BatchNormalization) (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "DO-C1-1 (Dropout)            (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "C3-4 (Conv2D)                (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "BN-C3-4 (BatchNormalization) (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "DO-C3-4 (Dropout)            (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "C1-2 (Conv2D)                (None, 9, 9, 10)          170       \n",
            "_________________________________________________________________\n",
            "BN-C1-2 (BatchNormalization) (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "DO-1-2 (Dropout)             (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "C3-5 (Conv2D)                (None, 7, 7, 16)          1456      \n",
            "_________________________________________________________________\n",
            "BN-C3-5 (BatchNormalization) (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "DO-C3-5 (Dropout)            (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "C7-1 (Conv2D)                (None, 1, 1, 10)          7850      \n",
            "_________________________________________________________________\n",
            "F (Flatten)                  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,708\n",
            "Trainable params: 14,528\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twZppaDl8FgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WCBH6WW_zoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "#early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "csv_logger = CSVLogger('/content/gdrive/My Drive/EVA/P3/Try2/mnist.csv')\n",
        "\n",
        "filepath=\"/content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "c5139161-53cd-4721-a9d3-96639df4c1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5252
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          callbacks=[csv_logger, checkpoint, LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 32s 536us/step - loss: 0.1839 - acc: 0.9415 - val_loss: 0.0619 - val_acc: 0.9799\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.97990, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0604 - acc: 0.9811 - val_loss: 0.0369 - val_acc: 0.9873\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.97990 to 0.98730, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0455 - acc: 0.9860 - val_loss: 0.0347 - val_acc: 0.9885\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98730 to 0.98850, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 20s 339us/step - loss: 0.0394 - acc: 0.9875 - val_loss: 0.0280 - val_acc: 0.9906\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98850 to 0.99060, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0328 - acc: 0.9897 - val_loss: 0.0274 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.99060 to 0.99110, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.0316 - val_acc: 0.9891\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99110\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0300 - acc: 0.9908 - val_loss: 0.0315 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99110\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0267 - acc: 0.9914 - val_loss: 0.0266 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99110 to 0.99150, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0224 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99150 to 0.99340, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.0231 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.99340 to 0.99360, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0226 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99360 to 0.99370, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0224 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.99370 to 0.99390, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0221 - acc: 0.9928 - val_loss: 0.0246 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99390\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0252 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99390\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0213 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99390\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0192 - acc: 0.9936 - val_loss: 0.0230 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99390\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0232 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99390\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 19s 325us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0227 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99390\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0176 - acc: 0.9941 - val_loss: 0.0230 - val_acc: 0.9944\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.99390 to 0.99440, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0163 - acc: 0.9944 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99440\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 19s 323us/step - loss: 0.0163 - acc: 0.9945 - val_loss: 0.0204 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99440\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0189 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.99440 to 0.99490, saving model to /content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0206 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99490\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0205 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99490\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0214 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99490\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 20s 338us/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0211 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99490\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0203 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99490\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0207 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99490\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 20s 338us/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0200 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99490\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0207 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99490\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0200 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99490\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0206 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99490\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0195 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99490\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0196 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99490\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0210 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99490\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0201 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99490\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0210 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99490\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 20s 332us/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0203 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99490\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0205 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99490\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0117 - acc: 0.9963 - val_loss: 0.0191 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99490\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.0199 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.99490\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0198 - val_acc: 0.9944\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.99490\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0197 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.99490\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "60000/60000 [==============================] - 19s 323us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0183 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.99490\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0111 - acc: 0.9961 - val_loss: 0.0200 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.99490\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0198 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.99490\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "60000/60000 [==============================] - 19s 322us/step - loss: 0.0115 - acc: 0.9959 - val_loss: 0.0212 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.99490\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.0197 - val_acc: 0.9948\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.99490\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0192 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.99490\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0193 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.99490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa907c6c160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COypMAljzOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading best model from the initial training\n",
        "model.load_weights(\"/content/gdrive/My Drive/EVA/P3/Try2/Iter4 - BestExp.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model on the test data\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "61b333cc-647a-4c84-e033-4e5e6b590e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Printing test score\n",
        "print(score)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01888107100098714, 0.9949]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}